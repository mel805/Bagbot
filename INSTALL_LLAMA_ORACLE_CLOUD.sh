#!/bin/bash

###############################################################################
# üöÄ Script d'Installation Automatique: Ollama + Llama sur Oracle Cloud
# 
# Ce script installe et configure Ollama avec Llama 3.2 sur une VM Oracle Cloud
# Compatible: ARM64 et x86_64
#
# Utilisation:
#   1. Cr√©er VM Oracle Cloud (ARM recommended: 4 CPU + 24 GB RAM - GRATUIT)
#   2. Copier ce script sur la VM: scp INSTALL_LLAMA_ORACLE_CLOUD.sh ubuntu@VM-IP:~/
#   3. Se connecter: ssh ubuntu@VM-IP
#   4. Ex√©cuter: bash INSTALL_LLAMA_ORACLE_CLOUD.sh
#
# Date: 24 D√©cembre 2025
###############################################################################

set -e  # Arr√™ter en cas d'erreur

# Couleurs
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Fonctions utilitaires
log() {
    echo -e "${BLUE}[$(date +'%H:%M:%S')]${NC} $1"
}

success() {
    echo -e "${GREEN}‚úì${NC} $1"
}

warning() {
    echo -e "${YELLOW}‚ö†${NC} $1"
}

error() {
    echo -e "${RED}‚úó${NC} $1"
}

header() {
    echo ""
    echo -e "${CYAN}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${NC}"
    echo -e "${CYAN}$1${NC}"
    echo -e "${CYAN}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${NC}"
    echo ""
}

###############################################################################
# CONFIGURATION
###############################################################################

# Mod√®le Llama √† installer (modifiable)
LLAMA_MODEL="${LLAMA_MODEL:-llama3.2:3b}"  # Options: 1b, 3b, 8b, 70b

# Port API Ollama
OLLAMA_PORT="${OLLAMA_PORT:-11434}"

# Autoriser acc√®s externe
OLLAMA_HOST="${OLLAMA_HOST:-0.0.0.0}"

###############################################################################
# √âTAPE 1: V√©rifications Pr√©liminaires
###############################################################################

header "√âTAPE 1/7: V√©rifications Syst√®me"

log "D√©tection de l'architecture..."
ARCH=$(uname -m)
success "Architecture: $ARCH"

log "D√©tection du syst√®me d'exploitation..."
if [ -f /etc/os-release ]; then
    . /etc/os-release
    OS=$ID
    VER=$VERSION_ID
    success "OS: $PRETTY_NAME"
else
    error "Impossible de d√©tecter l'OS"
    exit 1
fi

log "V√©rification des ressources..."
TOTAL_RAM=$(free -h | awk '/^Mem:/{print $2}')
TOTAL_DISK=$(df -h / | awk 'NR==2{print $4}')
CPU_CORES=$(nproc)

echo "  RAM disponible: $TOTAL_RAM"
echo "  Disque disponible: $TOTAL_DISK"
echo "  CPU cores: $CPU_CORES"

# V√©rifier RAM minimale (2 GB pour 1b, 4 GB pour 3b, 8 GB pour 8b)
TOTAL_RAM_MB=$(free -m | awk '/^Mem:/{print $2}')
if [[ "$LLAMA_MODEL" == *"8b"* ]] && [ $TOTAL_RAM_MB -lt 8000 ]; then
    warning "RAM insuffisante pour Llama 8B (besoin: 8+ GB, disponible: ${TOTAL_RAM_MB} MB)"
    warning "R√©duire √† 3b ou 1b recommand√©"
elif [[ "$LLAMA_MODEL" == *"3b"* ]] && [ $TOTAL_RAM_MB -lt 4000 ]; then
    warning "RAM insuffisante pour Llama 3B (besoin: 4+ GB, disponible: ${TOTAL_RAM_MB} MB)"
    warning "R√©duire √† 1b recommand√©"
elif [[ "$LLAMA_MODEL" == *"1b"* ]] && [ $TOTAL_RAM_MB -lt 2000 ]; then
    error "RAM insuffisante m√™me pour Llama 1B (besoin: 2+ GB, disponible: ${TOTAL_RAM_MB} MB)"
    exit 1
fi

success "Ressources suffisantes pour $LLAMA_MODEL"

###############################################################################
# √âTAPE 2: Mise √† Jour du Syst√®me
###############################################################################

header "√âTAPE 2/7: Mise √† Jour du Syst√®me"

log "Mise √† jour des paquets syst√®me..."
sudo apt-get update -qq
sudo apt-get upgrade -y -qq
success "Syst√®me √† jour"

log "Installation des d√©pendances de base..."
sudo apt-get install -y -qq \
    curl \
    wget \
    git \
    build-essential \
    ca-certificates \
    gnupg \
    lsb-release

success "D√©pendances install√©es"

###############################################################################
# √âTAPE 3: Installation d'Ollama
###############################################################################

header "√âTAPE 3/7: Installation d'Ollama"

log "V√©rification si Ollama est d√©j√† install√©..."
if command -v ollama &> /dev/null; then
    warning "Ollama d√©j√† install√©, version: $(ollama --version 2>/dev/null | head -1)"
    read -p "R√©installer Ollama? (y/N): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        success "Utilisation de l'installation existante"
    else
        log "R√©installation d'Ollama..."
        curl -fsSL https://ollama.com/install.sh | sh
        success "Ollama r√©install√©"
    fi
else
    log "T√©l√©chargement et installation d'Ollama..."
    curl -fsSL https://ollama.com/install.sh | sh
    success "Ollama install√© avec succ√®s"
fi

log "V√©rification de l'installation..."
if command -v ollama &> /dev/null; then
    success "Ollama install√©: $(ollama --version 2>/dev/null | head -1 || echo 'Version inconnue')"
else
    error "L'installation d'Ollama a √©chou√©"
    exit 1
fi

###############################################################################
# √âTAPE 4: Configuration du Service Ollama
###############################################################################

header "√âTAPE 4/7: Configuration du Service"

log "Configuration du service systemd pour Ollama..."

# Cr√©er ou modifier le service systemd
sudo systemctl stop ollama 2>/dev/null || true

log "Configuration de l'acc√®s externe (0.0.0.0:$OLLAMA_PORT)..."

# Cr√©er le fichier de configuration systemd override
sudo mkdir -p /etc/systemd/system/ollama.service.d/
sudo tee /etc/systemd/system/ollama.service.d/override.conf > /dev/null <<EOF
[Service]
Environment="OLLAMA_HOST=$OLLAMA_HOST:$OLLAMA_PORT"
Environment="OLLAMA_ORIGINS=*"
EOF

success "Configuration cr√©√©e: /etc/systemd/system/ollama.service.d/override.conf"

log "Rechargement de systemd..."
sudo systemctl daemon-reload

log "D√©marrage du service Ollama..."
sudo systemctl enable ollama
sudo systemctl start ollama

sleep 3

log "V√©rification du statut du service..."
if sudo systemctl is-active --quiet ollama; then
    success "Service Ollama actif"
else
    error "Le service Ollama n'a pas d√©marr√© correctement"
    log "Logs du service:"
    sudo journalctl -u ollama -n 20 --no-pager
    exit 1
fi

###############################################################################
# √âTAPE 5: T√©l√©chargement du Mod√®le Llama
###############################################################################

header "√âTAPE 5/7: T√©l√©chargement du Mod√®le $LLAMA_MODEL"

log "T√©l√©chargement de $LLAMA_MODEL (cela peut prendre plusieurs minutes)..."
warning "Taille approximative:"
case "$LLAMA_MODEL" in
    *"1b"*)
        echo "  Llama 3.2 1B: ~1.3 GB"
        ;;
    *"3b"*)
        echo "  Llama 3.2 3B: ~2.0 GB"
        ;;
    *"8b"*)
        echo "  Llama 3 8B: ~4.7 GB"
        ;;
    *"70b"*)
        echo "  Llama 2 70B: ~39 GB"
        ;;
esac

echo ""
log "D√©but du t√©l√©chargement..."
ollama pull $LLAMA_MODEL

if [ $? -eq 0 ]; then
    success "Mod√®le $LLAMA_MODEL t√©l√©charg√© avec succ√®s"
else
    error "√âchec du t√©l√©chargement du mod√®le"
    exit 1
fi

###############################################################################
# √âTAPE 6: Configuration du Firewall
###############################################################################

header "√âTAPE 6/7: Configuration du Firewall"

log "Configuration d'iptables pour autoriser le port $OLLAMA_PORT..."

# V√©rifier si ufw est install√© et actif
if command -v ufw &> /dev/null && sudo ufw status | grep -q "active"; then
    log "UFW d√©tect√©, ajout de la r√®gle..."
    sudo ufw allow $OLLAMA_PORT/tcp
    success "R√®gle UFW ajout√©e pour le port $OLLAMA_PORT"
else
    log "UFW non actif, ajout de r√®gle iptables..."
    sudo iptables -I INPUT -p tcp --dport $OLLAMA_PORT -j ACCEPT
    
    # Sauvegarder les r√®gles iptables
    if command -v netfilter-persistent &> /dev/null; then
        sudo netfilter-persistent save
        success "R√®gles iptables sauvegard√©es"
    else
        warning "netfilter-persistent non install√©, les r√®gles ne seront pas persistantes apr√®s reboot"
        log "Pour installer: sudo apt-get install iptables-persistent"
    fi
fi

warning "N'oubliez pas de configurer les Security Lists dans Oracle Cloud Console:"
echo "  1. Aller dans: Networking ‚Üí Virtual Cloud Networks ‚Üí Security Lists"
echo "  2. Ajouter Ingress Rule:"
echo "     - Source CIDR: 0.0.0.0/0"
echo "     - IP Protocol: TCP"
echo "     - Destination Port Range: $OLLAMA_PORT"

###############################################################################
# √âTAPE 7: Tests et Validation
###############################################################################

header "√âTAPE 7/7: Tests de Validation"

log "Attente du d√©marrage complet d'Ollama (10 secondes)..."
sleep 10

log "Test 1: V√©rification de l'API locale..."
if curl -s http://localhost:$OLLAMA_PORT/api/tags > /dev/null; then
    success "API locale accessible"
else
    error "API locale non accessible"
    log "V√©rification des logs:"
    sudo journalctl -u ollama -n 20 --no-pager
fi

log "Test 2: Liste des mod√®les install√©s..."
MODELS=$(curl -s http://localhost:$OLLAMA_PORT/api/tags | grep -o '"name":"[^"]*"' | cut -d'"' -f4)
if [ -n "$MODELS" ]; then
    success "Mod√®les install√©s:"
    echo "$MODELS" | while read -r model; do
        echo "  - $model"
    done
else
    error "Aucun mod√®le trouv√©"
fi

log "Test 3: G√©n√©ration de texte avec $LLAMA_MODEL..."
TEST_RESPONSE=$(curl -s -X POST http://localhost:$OLLAMA_PORT/api/generate \
    -d "{\"model\": \"$LLAMA_MODEL\", \"prompt\": \"Hello, how are you?\", \"stream\": false}" \
    -H "Content-Type: application/json")

if echo "$TEST_RESPONSE" | grep -q "response"; then
    success "G√©n√©ration de texte fonctionnelle"
    log "R√©ponse du mod√®le:"
    echo "$TEST_RESPONSE" | python3 -c "import sys, json; print(json.load(sys.stdin).get('response', 'N/A')[:200])" 2>/dev/null || echo "OK"
else
    error "La g√©n√©ration de texte a √©chou√©"
    echo "R√©ponse brute: $TEST_RESPONSE"
fi

log "Test 4: Acc√®s externe..."
EXTERNAL_IP=$(curl -s ifconfig.me || curl -s ipinfo.io/ip || echo "UNKNOWN")
if [ "$EXTERNAL_IP" != "UNKNOWN" ]; then
    success "IP publique d√©tect√©e: $EXTERNAL_IP"
    echo ""
    echo "  Testez depuis votre machine locale (ou Android):"
    echo "  ${GREEN}curl http://$EXTERNAL_IP:$OLLAMA_PORT/api/tags${NC}"
    echo ""
else
    warning "Impossible de d√©tecter l'IP publique"
fi

###############################################################################
# R√âSUM√â FINAL
###############################################################################

header "üéâ INSTALLATION TERMIN√âE AVEC SUCC√àS"

cat << EOF
${GREEN}‚úì${NC} Ollama install√© et configur√©
${GREEN}‚úì${NC} Mod√®le $LLAMA_MODEL t√©l√©charg√©
${GREEN}‚úì${NC} Service systemd actif et en √©coute sur ${OLLAMA_HOST}:${OLLAMA_PORT}
${GREEN}‚úì${NC} API REST accessible

${CYAN}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${NC}
${CYAN}Informations d'Acc√®s${NC}
${CYAN}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${NC}

${YELLOW}API Endpoint:${NC}
  http://$EXTERNAL_IP:$OLLAMA_PORT

${YELLOW}Mod√®le actif:${NC}
  $LLAMA_MODEL

${CYAN}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${NC}
${CYAN}Exemples d'Utilisation${NC}
${CYAN}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${NC}

${YELLOW}1. Test depuis Terminal:${NC}

curl -X POST http://$EXTERNAL_IP:$OLLAMA_PORT/api/generate \\
  -H "Content-Type: application/json" \\
  -d '{
    "model": "$LLAMA_MODEL",
    "prompt": "√âcris un po√®me sur l IA",
    "stream": false
  }'

${YELLOW}2. Code Android (Kotlin):${NC}

val client = OkHttpClient()
val json = JSONObject().apply {
    put("model", "$LLAMA_MODEL")
    put("prompt", "Bonjour Llama!")
    put("stream", false)
}

val request = Request.Builder()
    .url("http://$EXTERNAL_IP:$OLLAMA_PORT/api/generate")
    .post(json.toString().toRequestBody("application/json".toMediaType()))
    .build()

client.newCall(request).enqueue(object : Callback {
    override fun onResponse(call: Call, response: Response) {
        val result = JSONObject(response.body?.string() ?: "")
        val text = result.getString("response")
        println("Llama: \$text")
    }
    override fun onFailure(call: Call, e: IOException) {
        e.printStackTrace()
    }
})

${YELLOW}3. Chat interactif (sur le serveur):${NC}

ollama run $LLAMA_MODEL

${CYAN}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${NC}
${CYAN}Commandes Utiles${NC}
${CYAN}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${NC}

${YELLOW}G√©rer le service:${NC}
  sudo systemctl status ollama       # Statut
  sudo systemctl restart ollama      # Red√©marrer
  sudo systemctl stop ollama         # Arr√™ter
  sudo journalctl -u ollama -f       # Logs en temps r√©el

${YELLOW}G√©rer les mod√®les:${NC}
  ollama list                        # Liste des mod√®les
  ollama pull llama3.2:8b            # T√©l√©charger un autre mod√®le
  ollama rm $LLAMA_MODEL             # Supprimer un mod√®le
  ollama show $LLAMA_MODEL           # Infos sur le mod√®le

${YELLOW}Tester l'API:${NC}
  curl http://localhost:$OLLAMA_PORT/api/tags
  curl http://localhost:$OLLAMA_PORT/api/version

${CYAN}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${NC}
${CYAN}S√©curit√© & Configuration Oracle Cloud${NC}
${CYAN}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${NC}

${RED}‚ö† IMPORTANT:${NC} Vous devez configurer les Security Lists dans Oracle Cloud:

1. Connectez-vous √†: ${BLUE}https://cloud.oracle.com${NC}
2. Navigation ‚Üí Compute ‚Üí Instances ‚Üí [Votre Instance]
3. Resources ‚Üí Virtual Cloud Network ‚Üí Security Lists
4. Ingress Rules ‚Üí Add Ingress Rule:
   ${YELLOW}Source CIDR:${NC} 0.0.0.0/0
   ${YELLOW}IP Protocol:${NC} TCP
   ${YELLOW}Destination Port:${NC} $OLLAMA_PORT

${YELLOW}Pour une meilleure s√©curit√© (production):${NC}
- Utilisez un reverse proxy (Nginx) avec HTTPS
- Limitez l'acc√®s par IP (au lieu de 0.0.0.0/0)
- Ajoutez une authentification API (bearer token)
- Activez rate limiting

${CYAN}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${NC}
${CYAN}Monitoring & Performance${NC}
${CYAN}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${NC}

${YELLOW}Monitorer les ressources:${NC}
  htop                               # CPU/RAM en temps r√©el
  watch -n 1 nvidia-smi              # GPU (si disponible)
  df -h                              # Espace disque

${YELLOW}Tester la performance:${NC}
  time ollama run $LLAMA_MODEL "√âcris un court po√®me"

${YELLOW}Logs d√©taill√©s:${NC}
  sudo journalctl -u ollama --since "10 minutes ago"

${CYAN}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${NC}

${GREEN}üéä Tout est pr√™t! Vous pouvez maintenant utiliser Llama depuis votre application Android.${NC}

${YELLOW}Questions ou probl√®mes?${NC}
- Documentation Ollama: https://github.com/ollama/ollama/blob/main/docs/api.md
- Mod√®les disponibles: https://ollama.com/library

${GREEN}Bonne utilisation de Llama! üöÄ${NC}

EOF

# Sauvegarder les infos dans un fichier
cat > ~/OLLAMA_INFO.txt << EOF
Installation Date: $(date)
Ollama Version: $(ollama --version 2>/dev/null | head -1 || echo "Unknown")
Model: $LLAMA_MODEL
API Endpoint: http://$EXTERNAL_IP:$OLLAMA_PORT
Host: $OLLAMA_HOST
Port: $OLLAMA_PORT

Test Command:
curl http://$EXTERNAL_IP:$OLLAMA_PORT/api/tags
EOF

success "Informations sauvegard√©es dans ~/OLLAMA_INFO.txt"

exit 0
